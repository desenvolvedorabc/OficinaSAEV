#!/usr/bin/env python3
"""
Script para carregar dados dos arquivos Excel de alunos ES 
para a tabela alunos_es no banco DuckDB.

Arquivos de entrada:
- diag_ES_alunos_testes.xlsx  (833.564 registros)
- form1_ES_alunos_testes.xlsx (827.099 registros)

Total: ~1.6 milh√µes de registros (TODOS os registros, incluindo duplicatas)

Autor: Sistema SAEV
Data: 07/08/2025
"""

import pandas as pd
import duckdb
import sys
from pathlib import Path
import logging
from typing import List, Tuple

def setup_logging():
    """Configurar logging para acompanhar o processo"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)

def validate_files():
    """Validar se os arquivos necess√°rios existem"""
    excel_files = [
        Path("data/test/diag_ES_alunos_testes.xlsx"),
        Path("data/test/form1_ES_alunos_testes.xlsx")
    ]
    db_file = Path("db/avaliacao_prod.duckdb")
    
    for excel_file in excel_files:
        if not excel_file.exists():
            raise FileNotFoundError(f"‚ùå Arquivo Excel n√£o encontrado: {excel_file}")
    
    if not db_file.exists():
        raise FileNotFoundError(f"‚ùå Banco de dados n√£o encontrado: {db_file}")
    
    return excel_files, db_file

def load_excel_files(excel_files: List[Path]) -> pd.DataFrame:
    """Carregar e combinar dados dos arquivos Excel"""
    logger = logging.getLogger(__name__)
    
    dataframes = []
    total_records = 0
    
    for excel_file in excel_files:
        logger.info(f"üìä Carregando arquivo: {excel_file.name}")
        
        try:
            df = pd.read_excel(excel_file)
            
            # Validar colunas esperadas
            expected_columns = ['MUN_UF', 'MUN_NOME', 'ESC_ID', 'ESC_INEP', 'ESC_NOME', 
                              'SER_NOME', 'DIS_NOME', 'ALT_ALU_ID', 'ALU_NOME']
            missing_columns = set(expected_columns) - set(df.columns)
            
            if missing_columns:
                raise ValueError(f"‚ùå Colunas ausentes em {excel_file.name}: {missing_columns}")
            
            # Aplicar convers√µes de tipos conforme DDL
            df = convert_data_types(df)
            
            logger.info(f"‚úÖ {excel_file.name}: {len(df):,} registros carregados")
            dataframes.append(df)
            total_records += len(df)
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao carregar {excel_file.name}: {e}")
            raise
    
    # Combinar todos os DataFrames
    logger.info(f"üîó Combinando {len(dataframes)} arquivos...")
    combined_df = pd.concat(dataframes, ignore_index=True)
    
    logger.info(f"‚úÖ Total combinado: {len(combined_df):,} registros")
    logger.info(f"üìä Mantendo TODOS os registros (incluindo m√∫ltiplas avalia√ß√µes por aluno)")
    
    # Verificar duplicatas por ALT_ALU_ID apenas para informa√ß√£o (N√ÉO remover)
    duplicates = combined_df['ALT_ALU_ID'].duplicated().sum()
    unique_students = combined_df['ALT_ALU_ID'].nunique()
    if duplicates > 0:
        logger.info(f"üìä {duplicates} registros com ALT_ALU_ID repetido encontrados")
        logger.info(f"üéì {unique_students} alunos √∫nicos com m√∫ltiplas avalia√ß√µes")
        logger.info(f"üìö Mantendo todos os registros para preservar hist√≥rico de avalia√ß√µes")
    
    return combined_df

def convert_data_types(df: pd.DataFrame) -> pd.DataFrame:
    """Converter tipos de dados conforme especifica√ß√£o da tabela"""
    logger = logging.getLogger(__name__)
    
    try:
        # Convers√µes conforme DDL:
        # MUN_UF CHAR(2) -> string limitada a 2 caracteres
        df['MUN_UF'] = df['MUN_UF'].astype(str).str[:2]
        
        # MUN_NOME VARCHAR(60) -> string limitada a 60 caracteres  
        df['MUN_NOME'] = df['MUN_NOME'].astype(str).str[:60]
        
        # ESC_ID INTEGER -> garantir tipo inteiro
        df['ESC_ID'] = pd.to_numeric(df['ESC_ID'], errors='coerce').astype('Int64')
        
        # ESC_INEP VARCHAR -> string (mantendo ESC_INEO conforme DDL fornecido)
        df['ESC_INEP'] = df['ESC_INEP'].astype(str)
        
        # ESC_NOME VARCHAR -> string
        df['ESC_NOME'] = df['ESC_NOME'].astype(str)
        
        # SER_NOME VARCHAR -> string
        df['SER_NOME'] = df['SER_NOME'].astype(str)
        
        # DIS_NOME VARCHAR -> string
        df['DIS_NOME'] = df['DIS_NOME'].astype(str)
        
        # ALT_ALU_ID INTEGER -> garantir tipo inteiro
        df['ALT_ALU_ID'] = pd.to_numeric(df['ALT_ALU_ID'], errors='coerce').astype('Int64')
        
        # ALU_NOME VARCHAR -> string
        df['ALU_NOME'] = df['ALU_NOME'].astype(str)
        
        logger.info("‚úÖ Convers√µes de tipos aplicadas")
        
        # Verificar valores nulos ap√≥s convers√µes
        null_counts = df.isnull().sum()
        if null_counts.any():
            logger.warning("‚ö†Ô∏è Valores nulos ap√≥s convers√µes:")
            for col, count in null_counts[null_counts > 0].items():
                logger.warning(f"   {col}: {count} valores nulos")
        
        return df
        
    except Exception as e:
        logger.error(f"‚ùå Erro nas convers√µes de tipos: {e}")
        raise

def create_or_recreate_table(conn):
    """Criar ou recriar a tabela alunos_es"""
    logger = logging.getLogger(__name__)
    
    try:
        # Verificar se a tabela existe
        tables = conn.execute("SHOW TABLES").fetchall()
        table_names = [table[0] for table in tables]
        
        if 'alunos_es' in table_names:
            logger.info("üìä Tabela alunos_es existe - verificando registros...")
            count = conn.execute("SELECT COUNT(*) FROM alunos_es").fetchone()[0]
            logger.info(f"üóÇÔ∏è Registros existentes: {count:,}")
            
            # Limpar tabela
            conn.execute("DELETE FROM alunos_es")
            logger.info("üóëÔ∏è Tabela limpa")
        else:
            # Criar tabela conforme DDL fornecido (com ESC_INEO)
            logger.info("üèóÔ∏è Criando tabela alunos_es...")
            create_table_sql = """
            CREATE TABLE alunos_es (
                MUN_UF CHAR(2),
                MUN_NOME VARCHAR(60),
                ESC_ID INTEGER,
                ESC_INEO VARCHAR,
                ESC_NOME VARCHAR,
                SER_NOME VARCHAR,
                DIS_NOME VARCHAR,
                ALT_ALU_ID INTEGER,
                ALU_NOME VARCHAR
            )
            """
            conn.execute(create_table_sql)
            logger.info("‚úÖ Tabela criada com sucesso")
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao criar/limpar tabela: {e}")
        raise

def insert_data(conn, df: pd.DataFrame):
    """Inserir dados do DataFrame na tabela"""
    logger = logging.getLogger(__name__)
    
    try:
        logger.info("üì• Iniciando inser√ß√£o de dados...")
        logger.info(f"üìä Total de registros para inserir: {len(df):,}")
        
        # Preparar query de inser√ß√£o (usando ESC_INEO conforme DDL)
        insert_query = """
        INSERT INTO alunos_es (MUN_UF, MUN_NOME, ESC_ID, ESC_INEO, ESC_NOME, 
                              SER_NOME, DIS_NOME, ALT_ALU_ID, ALU_NOME)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        """
        
        # Converter DataFrame para lista de tuplas, tratando NaN
        data_tuples = []
        for _, row in df.iterrows():
            tuple_row = tuple(
                None if pd.isna(value) else value 
                for value in row
            )
            data_tuples.append(tuple_row)
        
        # Inserir dados em lotes para melhor performance
        batch_size = 5000  # Lotes maiores para arquivos grandes
        total_inserted = 0
        
        logger.info(f"üîÑ Inserindo em lotes de {batch_size:,} registros...")
        
        for i in range(0, len(data_tuples), batch_size):
            batch = data_tuples[i:i + batch_size]
            conn.executemany(insert_query, batch)
            total_inserted += len(batch)
            
            # Log a cada 100k registros
            if total_inserted % 100000 == 0 or total_inserted == len(data_tuples):
                progress = (total_inserted / len(data_tuples)) * 100
                logger.info(f"üìù Inseridos {total_inserted:,}/{len(data_tuples):,} registros ({progress:.1f}%)")
        
        # Confirmar inser√ß√£o
        final_count = conn.execute("SELECT COUNT(*) FROM alunos_es").fetchone()[0]
        logger.info(f"‚úÖ Inser√ß√£o conclu√≠da! Total de registros na tabela: {final_count:,}")
        
        # Estat√≠sticas finais
        stats_query = """
        SELECT 
            COUNT(*) as total_registros,
            COUNT(DISTINCT ESC_ID) as total_escolas,
            COUNT(DISTINCT MUN_NOME) as total_municipios,
            COUNT(DISTINCT ALT_ALU_ID) as alunos_unicos
        FROM alunos_es
        """
        stats = conn.execute(stats_query).fetchone()
        logger.info(f"üìä Estat√≠sticas finais:")
        logger.info(f"   ÔøΩ Total de registros: {stats[0]:,}")
        logger.info(f"   üè´ Escolas √∫nicas: {stats[1]:,}")
        logger.info(f"   üèõÔ∏è Munic√≠pios √∫nicos: {stats[2]:,}")
        logger.info(f"   üéì Alunos √∫nicos: {stats[3]:,}")
        logger.info(f"   üìö M√©dia de registros por aluno: {stats[0]/stats[3]:.1f}")
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao inserir dados: {e}")
        raise

def connect_database(db_file: Path):
    """Conectar ao banco DuckDB"""
    logger = logging.getLogger(__name__)
    
    try:
        logger.info(f"üîó Conectando ao banco: {db_file}")
        
        # Tentar conex√£o com tratamento de lock
        try:
            conn = duckdb.connect(str(db_file))
        except Exception as e:
            if "Conflicting lock" in str(e):
                logger.error("‚ùå Banco est√° bloqueado por outro processo (DBeaver, etc.)")
                logger.error("üí° Feche o DBeaver ou outros clientes conectados ao banco")
                raise ValueError("Banco bloqueado por outro processo")
            else:
                raise
        
        logger.info("‚úÖ Conex√£o estabelecida com sucesso")
        return conn
        
    except Exception as e:
        logger.error(f"‚ùå Erro ao conectar ao banco: {e}")
        raise

def main():
    """Fun√ß√£o principal"""
    logger = setup_logging()
    
    try:
        logger.info("üöÄ Iniciando carregamento de dados alunos ES")
        logger.info("üìÇ Arquivos: diag_ES_alunos_testes.xlsx + form1_ES_alunos_testes.xlsx")
        logger.info("üéØ Destino: Tabela alunos_es")
        logger.info("üìö MODO: Mantendo TODOS os registros (incluindo m√∫ltiplas avalia√ß√µes)")
        logger.info("=" * 70)
        
        # 1. Validar arquivos
        excel_files, db_file = validate_files()
        
        # 2. Carregar e combinar dados dos Excel
        combined_df = load_excel_files(excel_files)
        
        # 3. Conectar ao banco
        conn = connect_database(db_file)
        
        # 4. Criar/limpar tabela
        create_or_recreate_table(conn)
        
        # 5. Inserir dados
        insert_data(conn, combined_df)
        
        # 6. Fechar conex√£o
        conn.close()
        
        logger.info("=" * 70)
        logger.info("üéâ Carregamento conclu√≠do com sucesso!")
        logger.info(f"üìä {len(combined_df):,} registros de alunos ES carregados")
        
    except Exception as e:
        logger.error(f"üí• Erro durante o processo: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
